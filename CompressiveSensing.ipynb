{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecdb7af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ca7e6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "SEGMENT_LEN = 32000\n",
    "FRAME_SIZE = 160\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "LR = 1e-4\n",
    "EPOCHS = 10\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e04bb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_shift(arr, shift):\n",
    "    return np.roll(arr, shift)\n",
    "\n",
    "def least_number(a, b):\n",
    "    g = math.gcd(a, b)\n",
    "    return a // g, b // g\n",
    "def generate_matrix(N, M, P, Q):\n",
    "    row = np.concatenate([np.ones(M), np.zeros(N - M)])\n",
    "    rows = []\n",
    "    for _ in range(M):\n",
    "        rows.append(row)\n",
    "        row = circular_shift(row, M)\n",
    "    return np.array(rows)\n",
    "def apply_cs(audio, sensing_matrix, frame_size):\n",
    "    n_frames = len(audio) // frame_size\n",
    "    out = []\n",
    "    for i in range(n_frames):\n",
    "        frame = audio[i*frame_size:(i+1)*frame_size]\n",
    "        out.append(sensing_matrix @ frame)\n",
    "    return np.concatenate(out)\n",
    "def build_sensing_matrix(N, compression_ratio):\n",
    "    M = int(compression_ratio * N)\n",
    "    P, Q = least_number(M, N)\n",
    "    return generate_matrix(N, M, P, Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4df107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing cs_75 (75%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 14333/71933 [23:30<1:34:26, 10.16it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "48000 requested and 0 written",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 59\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Save\u001b[39;00m\n\u001b[0;32m     58\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, utt \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 59\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompressed_audio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Prevent file-handle & memory buildup\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m audio, compressed_audio\n",
      "File \u001b[1;32mc:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\numpy\\lib\\_npyio_impl.py:581\u001b[0m, in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[0;32m    580\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n\u001b[1;32m--> 581\u001b[0m     \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfix_imports\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfix_imports\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\numpy\\lib\\format.py:754\u001b[0m, in \u001b[0;36mwrite_array\u001b[1;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m--> 754\u001b[0m         \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    756\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39mnditer(\n\u001b[0;32m    757\u001b[0m                 array, flags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexternal_loop\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuffered\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzerosize_ok\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    758\u001b[0m                 buffersize\u001b[38;5;241m=\u001b[39mbuffersize, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[1;31mOSError\u001b[0m: 48000 requested and 0 written"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "SAMPLE_RATE = 16000\n",
    "FRAME_SIZE = 160\n",
    "SEGMENT_LEN = 64000   # or whatever you use\n",
    "\n",
    "AUDIO_DIR = \"LA\\\\ASVspoof2019_LA_eval\\\\flac\"\n",
    "SAVE_ROOT = \"TestData\"\n",
    "\n",
    "compression_levels = {\n",
    "    # \"cs_25\": 0.25,\n",
    "    # \"cs_50\": 0.50,\n",
    "    \"cs_75\": 0.75\n",
    "}\n",
    "\n",
    "\n",
    "os.makedirs(SAVE_ROOT, exist_ok=True)\n",
    "\n",
    "for folder, ratio in compression_levels.items():\n",
    "    save_dir = os.path.join(SAVE_ROOT, folder)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    sensing_matrix = build_sensing_matrix(FRAME_SIZE, ratio)\n",
    "\n",
    "    print(f\"\\nProcessing {folder} ({int(ratio*100)}%)\")\n",
    "\n",
    "    for fname in tqdm(os.listdir(AUDIO_DIR)):\n",
    "        if not fname.endswith(\".flac\"):\n",
    "            continue\n",
    "\n",
    "        utt = os.path.splitext(fname)[0]\n",
    "        audio_path = os.path.join(AUDIO_DIR, fname)\n",
    "\n",
    "        try:\n",
    "            # safer loading\n",
    "            audio, _ = librosa.load(\n",
    "                audio_path,\n",
    "                sr=SAMPLE_RATE,\n",
    "                mono=True\n",
    "            )\n",
    "\n",
    "            if audio.size == 0:\n",
    "                raise ValueError(\"Empty audio\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[SKIPPED] {fname}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Pad / trim\n",
    "        if len(audio) < SEGMENT_LEN:\n",
    "            audio = np.pad(audio, (0, SEGMENT_LEN - len(audio)))\n",
    "        else:\n",
    "            audio = audio[:SEGMENT_LEN]\n",
    "\n",
    "        # Apply CS\n",
    "        compressed_audio = apply_cs(audio, sensing_matrix, FRAME_SIZE)\n",
    "\n",
    "        # Save\n",
    "        save_path = os.path.join(save_dir, utt + \".npy\")\n",
    "        np.save(save_path, compressed_audio)\n",
    "\n",
    "        # Prevent file-handle & memory buildup\n",
    "        del audio, compressed_audio\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2791fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_4072\\2769638365.py\", line 2, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\torch\\__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\torch\\functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted: Models\\25% CS\\aasist_cs_25.pth → Models\\25% CS\\aasist_cs_25.pt\n",
      "Converted: Models\\25% CS\\rawformerL_cs_25.pth → Models\\25% CS\\rawformerL_cs_25.pt\n",
      "Converted: Models\\25% CS\\rawnet2_cs_25.pth → Models\\25% CS\\rawnet2_cs_25.pt\n",
      "Converted: Models\\25% CS\\rawtfnet_16_cs_25.pth → Models\\25% CS\\rawtfnet_16_cs_25.pt\n",
      "Converted: Models\\25% CS\\rawtfnet_32_cs_25.pth → Models\\25% CS\\rawtfnet_32_cs_25.pt\n",
      "Converted: Models\\50% CS\\aasist_cs_50.pth → Models\\50% CS\\aasist_cs_50.pt\n",
      "Converted: Models\\50% CS\\rawformerL_50_cs.pth → Models\\50% CS\\rawformerL_50_cs.pt\n",
      "Converted: Models\\50% CS\\rawnet2_cs_50.pth → Models\\50% CS\\rawnet2_cs_50.pt\n",
      "Converted: Models\\50% CS\\rawtfnet_cs_best32.pth → Models\\50% CS\\rawtfnet_cs_best32.pt\n",
      "Converted: Models\\50% CS\\rawtfnet_cs_best_16.pth → Models\\50% CS\\rawtfnet_cs_best_16.pt\n",
      "Converted: Models\\75% CS\\aasist_cs_75.pth → Models\\75% CS\\aasist_cs_75.pt\n",
      "Converted: Models\\75% CS\\rawformerL_cs_75.pth → Models\\75% CS\\rawformerL_cs_75.pt\n",
      "Converted: Models\\75% CS\\rawnet2_cs_75.pth → Models\\75% CS\\rawnet2_cs_75.pt\n",
      "Converted: Models\\75% CS\\rawtfnet_16_cs_75.pth → Models\\75% CS\\rawtfnet_16_cs_75.pt\n",
      "Converted: Models\\75% CS\\rawtfnet_32_cs_75.pth → Models\\75% CS\\rawtfnet_32_cs_75.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "ROOT_DIR = \"Models\"   # change if needed\n",
    "\n",
    "sub_dirs = [\"25% CS\", \"50% CS\", \"75% CS\"]\n",
    "\n",
    "for sub in sub_dirs:\n",
    "    sub_path = os.path.join(ROOT_DIR, sub)\n",
    "\n",
    "    for file in os.listdir(sub_path):\n",
    "        if file.endswith(\".pth\"):\n",
    "            pth_path = os.path.join(sub_path, file)\n",
    "\n",
    "            # Load the model/checkpoint\n",
    "            checkpoint = torch.load(pth_path, map_location=\"cpu\")\n",
    "\n",
    "            # Create .pt filename\n",
    "            pt_name = file.replace(\".pth\", \".pt\")\n",
    "            pt_path = os.path.join(sub_path, pt_name)\n",
    "\n",
    "            # Save as .pt\n",
    "            torch.save(checkpoint, pt_path)\n",
    "\n",
    "            print(f\"Converted: {pth_path} → {pt_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
