{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e248e239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\bhatt\\AppData\\Local\\Temp\\ipykernel_22760\\1251437928.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\torch\\__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\torch\\functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\bhatt\\miniconda3\\envs\\torch118\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# =========================\n",
    "# -------- RawTFNet --------\n",
    "# =========================\n",
    "\n",
    "class TFAttention(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // 4)\n",
    "        self.fc2 = nn.Linear(channels // 4, channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = x.mean(dim=2)\n",
    "        w = F.relu(self.fc1(w))\n",
    "        w = torch.sigmoid(self.fc2(w)).unsqueeze(-1)\n",
    "        return x * w\n",
    "\n",
    "\n",
    "class TFResidualBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_ch, out_ch, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(out_ch)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(out_ch, out_ch, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(out_ch)\n",
    "\n",
    "        self.att = TFAttention(out_ch)\n",
    "        self.act = nn.LeakyReLU(0.3)\n",
    "\n",
    "        self.skip = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
    "        self.pool = nn.MaxPool1d(3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.skip(x)\n",
    "        x = self.act(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x = self.att(x)\n",
    "        x = self.act(x + identity)\n",
    "        return self.pool(x)\n",
    "\n",
    "\n",
    "class RawTFNet(nn.Module):\n",
    "    def __init__(self, base_channels=32):\n",
    "        super().__init__()\n",
    "\n",
    "        self.frontend = nn.Sequential(\n",
    "            nn.Conv1d(1, base_channels, 251, padding=125),\n",
    "            nn.BatchNorm1d(base_channels),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.MaxPool1d(3)\n",
    "        )\n",
    "\n",
    "        self.block1 = TFResidualBlock(base_channels, base_channels * 2)\n",
    "        self.block2 = TFResidualBlock(base_channels * 2, base_channels * 4)\n",
    "        self.block3 = TFResidualBlock(base_channels * 4, base_channels * 8)\n",
    "\n",
    "        self.gru = nn.GRU(base_channels * 8, 512, batch_first=True)\n",
    "        self.fc1 = nn.Linear(512, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.frontend(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.gru(x)\n",
    "        x = F.normalize(self.fc1(x[:, -1]), dim=1)\n",
    "        return self.fc2(x)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# -------- RawNet2 --------\n",
    "# =========================\n",
    "class FixedSincConv(nn.Module):\n",
    "    def __init__(self, out_channels=128, kernel_size=129, sample_rate=16000):\n",
    "        super().__init__()\n",
    "\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "        # Linear-scale fixed filterbank (S3 setup in paper)\n",
    "        low_hz = 0\n",
    "        high_hz = sample_rate // 2\n",
    "        hz = torch.linspace(low_hz, high_hz, out_channels + 1)\n",
    "\n",
    "        self.low = hz[:-1]\n",
    "        self.high = hz[1:]\n",
    "\n",
    "        n = torch.arange(-(kernel_size // 2), kernel_size // 2 + 1)\n",
    "        self.register_buffer(\"n\", n)\n",
    "        self.register_buffer(\"window\", torch.hamming_window(kernel_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        filters = []\n",
    "\n",
    "        for low, high in zip(self.low, self.high):\n",
    "            f1 = low / self.sample_rate\n",
    "            f2 = high / self.sample_rate\n",
    "            n = self.n.to(device)\n",
    "\n",
    "            sinc1 = torch.sin(2 * math.pi * f1 * n) / (n + 1e-9)\n",
    "            sinc2 = torch.sin(2 * math.pi * f2 * n) / (n + 1e-9)\n",
    "            band = (sinc2 - sinc1) * self.window.to(device)\n",
    "            filters.append(band)\n",
    "\n",
    "        filters = torch.stack(filters).view(self.out_channels, 1, self.kernel_size)\n",
    "        return F.conv1d(x, filters, stride=1, padding=self.kernel_size // 2)\n",
    "\n",
    "class FMS(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(channels, channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = x.mean(dim=2)\n",
    "        s = torch.sigmoid(self.fc(s))\n",
    "        s = s.unsqueeze(2)\n",
    "        return x * s + s\n",
    "\n",
    "\n",
    "class RawNetResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(channels, channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(channels)\n",
    "        self.conv2 = nn.Conv1d(channels, channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(channels)\n",
    "\n",
    "        self.fms = FMS(channels)\n",
    "        self.pool = nn.MaxPool1d(3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)), 0.3)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)), 0.3)\n",
    "        x = x + residual\n",
    "        x = self.pool(x)\n",
    "        x = self.fms(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RawNet2_AntiSpoof(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sinc = FixedSincConv(out_channels=128, kernel_size=129)\n",
    "        self.bn0 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            RawNetResidualBlock(128),\n",
    "            RawNetResidualBlock(128)\n",
    "        )\n",
    "\n",
    "        self.conv_expand = nn.Conv1d(128, 512, 1)\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            RawNetResidualBlock(512),\n",
    "            RawNetResidualBlock(512),\n",
    "            RawNetResidualBlock(512),\n",
    "            RawNetResidualBlock(512)\n",
    "        )\n",
    "\n",
    "        self.gru = nn.GRU(512, 1024, batch_first=True)\n",
    "        self.fc1 = nn.Linear(1024, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sinc(x)\n",
    "        x = F.leaky_relu(self.bn0(x), 0.3)\n",
    "\n",
    "        x = self.block1(x)\n",
    "        x = self.conv_expand(x)\n",
    "        x = self.block2(x)\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        self.gru.flatten_parameters()\n",
    "        x, _ = self.gru(x)\n",
    "\n",
    "        x = x[:, -1, :]\n",
    "        x = F.leaky_relu(self.fc1(x), 0.3)\n",
    "        return self.fc2(x)\n",
    "    \n",
    "    \n",
    "# =========================\n",
    "# -------- AASIST --------\n",
    "# =========================\n",
    "class AASIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.frontend = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, 251, padding=125),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.MaxPool1d(3)\n",
    "        )\n",
    "\n",
    "        self.block1 = STBlock(64, 128)\n",
    "        self.block2 = STBlock(128, 256)\n",
    "        self.block3 = STBlock(256, 512)\n",
    "\n",
    "        self.gru = nn.GRU(512, 512, batch_first=True)\n",
    "        self.fc1 = nn.Linear(512, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.frontend(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.gru(x)\n",
    "\n",
    "        x = F.normalize(self.fc1(x[:, -1]), dim=1)\n",
    "        return self.fc2(x)\n",
    "\n",
    "class STBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm1d(out_ch),\n",
    "            nn.LeakyReLU(0.3),\n",
    "\n",
    "            # ðŸ”¥ extra downsampling BEFORE attention\n",
    "            nn.MaxPool1d(4)\n",
    "        )\n",
    "\n",
    "        self.attn = TemporalSelfAttention(out_ch, heads=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)          # (B, C, Tâ†“)\n",
    "        x = x.permute(0, 2, 1)    # (B, Tâ†“, C)\n",
    "        x = self.attn(x)\n",
    "        return x.permute(0, 2, 1)\n",
    "\n",
    "\n",
    "class TemporalSelfAttention(nn.Module):\n",
    "    def __init__(self, dim, heads=4):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim=dim,\n",
    "            num_heads=heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, C)\n",
    "        out, _ = self.attn(x, x, x)\n",
    "        return out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# -------- RawformerL --------\n",
    "# =========================\n",
    "class RawFormerL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.frontend = nn.Sequential(\n",
    "            nn.Conv1d(1, 128, kernel_size=251, stride=5, padding=125),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.MaxPool1d(3),\n",
    "\n",
    "            nn.Conv1d(128, 256, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.3),\n",
    "            nn.MaxPool1d(3)\n",
    "        )\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=256,\n",
    "            nhead=8,\n",
    "            dim_feedforward=1024,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=4\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)          # (B,1,T)\n",
    "        x = self.frontend(x)        # (B,256,T')\n",
    "        x = x.permute(0, 2, 1)      # (B,T',256)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        mean = x.mean(dim=1)\n",
    "        std = x.std(dim=1)\n",
    "        stats = torch.cat([mean, std], dim=1)  # (B,512)\n",
    "\n",
    "        return self.fc(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7963f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eer(scores, labels):\n",
    "    fpr, tpr, _ = roc_curve(labels, scores, pos_label=1)\n",
    "    fnr = 1 - tpr\n",
    "    return 100 * fpr[np.nanargmin(np.abs(fnr - fpr))]\n",
    "def compute_min_tDCF(scores, labels):\n",
    "    Ptar, Cmiss, Cfa = 0.01, 1, 1\n",
    "    fpr, tpr, _ = roc_curve(labels, scores, pos_label=1)\n",
    "    fnr = 1 - tpr\n",
    "    return np.min(Cmiss * Ptar * fnr + Cfa * (1 - Ptar) * fpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d8e0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ProtocolNPYTestDataset(Dataset):\n",
    "    def __init__(self, root_dir, protocol_path):\n",
    "        self.samples = []\n",
    "\n",
    "        # -------------------------\n",
    "        # Read protocol file\n",
    "        # -------------------------\n",
    "        label_dict = {}\n",
    "\n",
    "        with open(protocol_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                utt_id = parts[1]  # ASVspoof ID\n",
    "                label = 1 if parts[-1] == \"spoof\" else 0\n",
    "                label_dict[utt_id] = label\n",
    "\n",
    "        # -------------------------\n",
    "        # Match .npy files to protocol\n",
    "        # -------------------------\n",
    "        for f in os.listdir(root_dir):\n",
    "            if f.endswith(\".npy\"):\n",
    "\n",
    "                utt_id = os.path.splitext(f)[0]\n",
    "\n",
    "                if utt_id in label_dict:\n",
    "                    path = os.path.join(root_dir, f)\n",
    "                    self.samples.append((path, label_dict[utt_id]))\n",
    "\n",
    "        print(f\"[INFO] Loaded {len(self.samples)} files from {root_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "\n",
    "        audio = np.load(path)\n",
    "\n",
    "        return (\n",
    "            torch.tensor(audio, dtype=torch.float32),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_test_loader(test_path):\n",
    "\n",
    "    protocol_path = \"LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\"\n",
    "\n",
    "    dataset = ProtocolNPYTestDataset(test_path, protocol_path)\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=False,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b0e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model: aasist_cs_25.pth\n",
      "Evaluating Train 25 â†’ Test 25\n",
      "[INFO] Loaded 71237 files from TestData\\cs_25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "TRAIN_RATIOS = [\"25\", \"50\", \"75\"]\n",
    "TEST_RATIOS = [\"25\", \"50\", \"75\"]\n",
    "\n",
    "MODEL_ROOT = \"ModelsSaved\"\n",
    "TEST_ROOT = \"TestData\"\n",
    "\n",
    "# -----------------------\n",
    "# Model factory\n",
    "# -----------------------\n",
    "\n",
    "def get_model(model_name):\n",
    "    if model_name == \"aasist\":\n",
    "        return AASIST()\n",
    "    elif model_name == \"rawnet2\":\n",
    "        return RawNet2_AntiSpoof()\n",
    "    elif model_name == \"rawformerL\":\n",
    "        return RawFormerL()\n",
    "    elif model_name == \"rawtfnet_16\":\n",
    "        return RawTFNet(base_channels=16)\n",
    "    elif model_name == \"rawtfnet_32\":\n",
    "        return RawTFNet(base_channels=32)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "\n",
    "# -----------------------\n",
    "# Evaluation loop\n",
    "# -----------------------\n",
    "\n",
    "results = []\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, model_name):\n",
    "    model.eval()\n",
    "\n",
    "    scores = []\n",
    "    labels = []\n",
    "\n",
    "    for x, y in loader:\n",
    "\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "\n",
    "        # RawNet2 expects (B,1,T)\n",
    "        if model_name == \"rawnet2\":\n",
    "            x = x.unsqueeze(1)\n",
    "\n",
    "        logits = model(x)\n",
    "\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        spoof_scores = probs[:, 1]  # probability of spoof\n",
    "\n",
    "        scores.extend(spoof_scores.cpu().numpy())\n",
    "        labels.extend(y.cpu().numpy())\n",
    "\n",
    "    return np.array(scores), np.array(labels)\n",
    "\n",
    "for train_ratio in TRAIN_RATIOS:\n",
    "\n",
    "    train_folder = os.path.join(MODEL_ROOT, f\"{train_ratio}% CS\")\n",
    "\n",
    "    for model_file in os.listdir(train_folder):\n",
    "\n",
    "        if not model_file.endswith(\".pth\"):\n",
    "            continue\n",
    "\n",
    "        model_name = model_file.replace(f\"_cs_{train_ratio}.pth\", \"\")\n",
    "        model_path = os.path.join(train_folder, model_file)\n",
    "\n",
    "        print(f\"\\nLoading model: {model_file}\")\n",
    "\n",
    "        model = get_model(model_name).to(DEVICE)\n",
    "        checkpoint = torch.load(model_path, map_location=DEVICE)\n",
    "        model.load_state_dict(checkpoint[\"model\"])        \n",
    "        model.eval()\n",
    "\n",
    "        for test_ratio in TEST_RATIOS:\n",
    "\n",
    "            print(f\"Evaluating Train {train_ratio} â†’ Test {test_ratio}\")\n",
    "\n",
    "            test_loader = get_test_loader(\n",
    "                os.path.join(TEST_ROOT, f\"cs_{test_ratio}\")\n",
    "            )\n",
    "\n",
    "            scores, labels = evaluate(model, test_loader, model_name)\n",
    "\n",
    "            eer = compute_eer(scores, labels)\n",
    "            tdcf = compute_min_tDCF(scores, labels)\n",
    "\n",
    "            results.append({\n",
    "                \"Model\": model_name,\n",
    "                \"Train_CS\": train_ratio,\n",
    "                \"Test_CS\": test_ratio,\n",
    "                \"EER\": eer,\n",
    "                \"min_tDCF\": tdcf\n",
    "            })\n",
    "\n",
    "# -----------------------\n",
    "# Save results\n",
    "# -----------------------\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"CS_Robustness_Results.csv\", index=False)\n",
    "\n",
    "print(\"\\nEvaluation complete. Results saved to CS_Robustness_Results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
